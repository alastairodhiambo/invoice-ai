import requests
import os
from transformers import pipeline
import pandas as pd
from fastapi import FastAPI, UploadFile

from invoice import extract_invoice
from to_csv import json_to_csv
from text2code import get_coordinates

from pydantic import BaseModel

# from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

# origins = [
#     "http://localhost",
#     "http://localhost:3000",
# ]

# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=origins,
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )


class Item(BaseModel):
    query: str | None = None


app = FastAPI()


@app.get("/")
def read_root():
    return {"Sanity": "Check"}


@app.post("/uploadfile/")
async def create_upload_file(file: UploadFile):
    data = extract_invoice(file.file).replace('\n', '').replace("'", '"')
    json_to_csv(data)

    return {"data": data}


@app.get("/process")
async def get_text(string: str):
    # Call the text2code function to process the input_text
    processed_result = get_coordinates(string)
    print(processed_result)

    # Return the processed result to the frontend
    return processed_result


# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-uv9FsKfBLLFkT1eBLsqIYKi9ZALJBEY
"""


# pip install transformers

model_checkpoint = "huggingface-course/bert-finetuned-ner"
token_classifier = pipeline(
    "token-classification", model=model_checkpoint, aggregation_strategy="simple"
)


def split_on_and(input_string):
    split_words = input_string.split('and')
    words_before = split_words[0].strip().split()
    word_before = words_before[-1] if words_before else ''
    word_after = split_words[1].strip().split()[
        0] if len(split_words) > 1 else ''
    return word_before, word_after


def get_highest_objects(string, data, df):
    highest_score = -1
    highest_org = None

    for item in data:
        if (item['entity_group'] == 'ORG' or item['entity_group'] == 'PER') and item['score'] > highest_score:
            highest_score = item['score']
            highest_org = "Place equals " + item['word']
    for item in data:
        if item['entity_group'] == 'LOC' and item['score'] > highest_score:
            highest_score = item['score']
            highest_loc = item['word']
            highest_loc = "Address contains " + highest_loc
    word_before, word_after = split_on_and(string)
    prompt = f"write a function called generated_function that returns two lists of the values {word_before} {word_after} columns from inputed dataframe df where {highest_org}"
    print(prompt)
    return prompt


def prompt(insert_prompt):
    CODEPAL_API_KEY = 'f796e543-5b48-4476-b8bb-3da3c6e3fee4'
    headers = {
        # Already added when you pass json= but not when you pass data=
        # 'Content-Type': 'application/json',
        'Authorization': f"Bearer {CODEPAL_API_KEY}",
    }
    print(headers)
    files = {
        'language': (None, 'python'),
        'instructions': (None, insert_prompt),
    }
    response = requests.post(
        'https://api.codepal.ai/v1/code-generator/query', headers=headers, files=files)
    result = response.json()
    print(result)
    return result


def write_to_py_file(string):
    text_file = open("function1.py", "w")
    n = text_file.write(string)
    text_file.close()
